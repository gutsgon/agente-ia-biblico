# Agente de IA BÃ­blico no WhatsApp (TCC)

## ğŸ“– VisÃ£o Geral do Projeto

Este projeto tem como objetivo desenvolver um **agente de InteligÃªncia Artificial** capaz de responder perguntas bÃ­blicas diretamente pelo **WhatsApp**, auxiliando usuÃ¡rios em **estudos bÃ­blicos rasos ou aprofundados**.

O agente utiliza tÃ©cnicas de **RAG (Retrieval-Augmented Generation)** para buscar trechos relevantes da BÃ­blia e fornecer respostas contextualizadas, mantendo fidelidade ao texto bÃ­blico.

O projeto foi idealizado para fins **acadÃªmicos (TCC)**, com foco em:
- Arquitetura bem definida
- Reprodutibilidade
- SeguranÃ§a de dados
- Processos claros de inicializaÃ§Ã£o e recuperaÃ§Ã£o

---

## ğŸ§  Tecnologias Utilizadas

- **Ollama** â€“ ExecuÃ§Ã£o de modelos LLM localmente
  - `gemma3:4b` â†’ geraÃ§Ã£o de respostas (modelo principal) 
  - `llama3.2:3b` â†’ geraÃ§Ã£o de respostas (modelo de fallback)
  - `llama3.1:8b` â†’ geraÃ§Ã£o de respostas (modelo reserva)

- **Ollama** - ExecuÃ§Ã£o de modelos de embedding para RAG localmente
  - `bge-m3` â†’ embeddings para RAG (modelo principal)
  - `nomic-embed-text` â†’ embeddings para RAG (modelo reserva)

- **Qdrant** â€“ Banco vetorial
- **PostgreSQL** â€“ PersistÃªncia de dados do Evolution API
- **Evolution API** â€“ IntegraÃ§Ã£o com WhatsApp
- **Docker / Docker Compose**
- **Linux (Ubuntu Server)**

---

## ğŸ—ï¸ Arquitetura (VisÃ£o Geral)

```
WhatsApp
   â†“
Evolution API
   â†“
Agente IA (RAG)
   â†“
N8N
   â†“
Ollama â”€â”€ Qdrant
   â†“
PostgreSQL
```

---

## ğŸš€ InicializaÃ§Ã£o do Ambiente

### 1ï¸âƒ£ Subir os containers

```bash
docker compose up -d
```

---

## ğŸ¤– ConfiguraÃ§Ã£o do Ollama

O Ollama **nÃ£o vem com modelos por padrÃ£o**. Para o projeto Ã© necessÃ¡rio um LLM e um para o embedding e RAG (caso tenha dÃºvidas sobre os modelos leia novamente acima em **Tecnologias**). Para baixar os modelos execute:

```bash
docker exec -it ollama ollama pull gemma3:4b 
docker exec -it ollama ollama pull llama3.2:3b 
docker exec -it ollama ollama pull llama3.1:8b 
docker exec -it ollama ollama pull nomic-embed-text 
docker exec -it ollama pull bge-m3 
```

Verifique:

```bash
docker exec -it ollama ollama list
```

Para rodar um modelo execute (exemplo):

```bash
docker exec -it ollama ollama run gemma3:4b
docker exec -it ollama ollama run bge-m3
```

## Uso de RAG (Retrieval-Augmented Generation)

Para evitar respostas baseadas exclusivamente em conhecimento prÃ©-treinado do modelo, foi adotada a abordagem RAG (Retrieval-Augmented Generation).

Os textos bÃ­blicos sÃ£o previamente vetorizados e armazenados no banco vetorial Qdrant. A cada pergunta, apenas trechos semanticamente relevantes sÃ£o recuperados e fornecidos como contexto ao modelo de linguagem.

Essa abordagem garante:
- ReduÃ§Ã£o de alucinaÃ§Ãµes
- Maior fidelidade textual
- Melhor desempenho computacional
- Rastreabilidade das respostas

---


## ğŸ“¦ PersistÃªncia de Dados

Todos os dados sÃ£o salvos em:

```text
/home/user/docker-data/
â”œâ”€â”€ postgres/
â”œâ”€â”€ qdrant/
â”œâ”€â”€ ollama/
â””â”€â”€ backups/
```

Isso garante **resistÃªncia Ã  perda de dados** e facilita backups.

---

## ğŸ’¾ Backup AutomÃ¡tico

O backup Ã© feito via script Bash utilizando `cron`.

### ExecuÃ§Ã£o manual:
```bash
/backup/backup.sh
```

### Cron (exemplo):
```bash
0 2 * * * /backup/backup.sh
```

Os backups incluem:
- PostgreSQL
- Qdrant
- Dados do Ollama

---

## â™»ï¸ RestauraÃ§Ã£o de Backup

### PostgreSQL
```bash
docker exec -i postgres psql -U postgres evolution_db < backup.sql
```

### Qdrant
```bash
docker compose down
cp -r backup/qdrant/* /home/paulo/docker-data/qdrant/
docker compose up -d
```

### Ollama
```bash
cp -r backup/ollama/* /home/paulo/docker-data/ollama/
```

---

## ğŸ§ª Objetivo AcadÃªmico

Este agente visa:
- Democratizar o acesso ao estudo bÃ­blico
- Auxiliar lÃ­deres, estudantes e curiosos
- Servir como **prova de conceito** para uso de IA em contextos educacionais e religiosos

---

## âœ… Checklist Antiâ€‘Perda de Dados

- [x] Volumes persistentes fora do Docker
- [x] Backup automÃ¡tico diÃ¡rio
- [x] DocumentaÃ§Ã£o de restauraÃ§Ã£o
- [x] Modelos versionados
- [x] Processo de inicializaÃ§Ã£o documentado

---

## ğŸ“Œ ObservaÃ§Ãµes Finais

Este projeto prioriza:
- Clareza de processos
- Reprodutibilidade acadÃªmica
- SeguranÃ§a e integridade dos dados

Qualquer reinstalaÃ§Ã£o do sistema **nÃ£o compromete o projeto**, desde que os backups estejam preservados.

---

âœï¸ *â€œLÃ¢mpada para os meus pÃ©s Ã© a tua palavra, e luz para o meu caminho.â€* â€“ Salmos 119:105
